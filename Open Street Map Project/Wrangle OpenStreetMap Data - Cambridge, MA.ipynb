{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle OpenStreetMap Data\n",
    "## Cambridge, MA\n",
    "\n",
    "I live very close to Cambridge. I go to Cambridge Public Library nearly every week to play go. Therefore, I am interested in finding out a bit more about the town. I have chosen to assess OpenStreetMap's data around Cambridge. To be more precise, I will be analyzing the data in the box created by the following lattitudes and longitudes.\n",
    "\n",
    "```\n",
    "MIN_LAT = 42.3409\n",
    "MAX_LAT = 42.4162\n",
    "MIN_LON = -71.1995\n",
    "MAX_LON = -71.0251\n",
    "```\n",
    "\n",
    "In order to find out more about one of my favorite areas in the world, I will not only need to get the data, but also perform some housekeeping to clean and organize the data. If possible, I also want to see if I can help improve Open Street Map project's data about Cambridge. I will start by seeing what kind of data I am getting, then I will investigate what's the best way to programmatically improve the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interesting Encounters in the Data\n",
    "\n",
    "## Nodes Not in the Box\n",
    "\n",
    "This was a little unexpected. As a sanity check, I tested to make sure that all nodes laid within the box of interest. To my surprise, a significant number of the nodes appeared to be outside of the box that I defined.\n",
    "\n",
    "There were 769,476 nodes in my dataset. 14,135 nodes were outside of the box. It's less than 2% of the total number of nodes, but this is definitely higher than I expected. However, these nodes are easily filtered out.\n",
    "\n",
    "## 0 - 11 Year Old Data\n",
    "\n",
    "While map data might not change very quickly, it does change. A business might have opening a new location, or closed down one of its store fronts. Because I am in Cambridge fairly often, I know that Toscanini's, which offers the best ice cream in Boston, has moved to a temporary location as its building is being renovated. However, this information might not show up if the information related to Tuscanini's is more than 6 months old.\n",
    "\n",
    "There is a not insignificant range for when the data was last captured. Most of the information seems to have been gather between 2009 - 2013.\n",
    "\n",
    "```\n",
    "2007: 6070\n",
    "2008: 1846\n",
    "2009: 443962\n",
    "2010: 43823\n",
    "2011: 40810\n",
    "2012: 45535\n",
    "2013: 163541\n",
    "2014: 29466\n",
    "2015: 23821\n",
    "2016: 49911\n",
    "2017: 29060\n",
    "2018: 20020\n",
    "```\n",
    "\n",
    "## Bewildering Organization of Data\n",
    "\n",
    "The organization of the data seems haphazard in \"node_tags\" and \"way_tags\". There does not seem to exist a standard way to input description of a feature on the node or way into the node and way tags system. Beyond \"id\" field, which is a numeric id, value, key and type information seemed to be mixed together. Value information seems to vary especially broadly. It ranges from telephone numbers, to an URL, and to a short paragraph description.\n",
    "\n",
    "## Meet the Maker\n",
    "\n",
    "It is perhaps expected from Pareto Principle that vast majority of the edits are contributed by a few users. I would hazard a guess that many of the major contributors also used an automated way to generate their edits. Subsequently, people who have a special interest in a particular location filled in more details or correct whatever was wrong with the previous data point.\n",
    "\n",
    "Another unexpected discovery that came out of this was that most node nodes were created once and never updated. While way nodes were updated more often. On average, a way node was created and then just update once. This makes me question how up to date the information on this patch of Open Street Maps are, when we combine this discover with the discovery that most of the information was created in 2009-2013. \n",
    "\n",
    "User Node Creators:\n",
    "\n",
    "```\n",
    "Top 10 out of 999:\n",
    "\n",
    "crschmidt -- 432,048\n",
    "jremillard-massgis -- 50,764\n",
    "OceanVortex -- 37,770\n",
    "morganwahl -- 27,495\n",
    "ryebread -- 25,199\n",
    "ingalls_imports -- 18,497\n",
    "mapper999 -- 11,238\n",
    "cspanring -- 5,826\n",
    "JasonWoof -- 5,548\n",
    "\n",
    "277/999 have only made one edit.\n",
    "\n",
    "Total Node Edits: 957,679 for 755,341 node nodes\n",
    "```\n",
    "\n",
    "Way Node Creators:\n",
    "\n",
    "```\n",
    "Top 10 out of 771:\n",
    "\n",
    "jremillard-massgis -- 82,295\n",
    "ryebread -- 6,899\n",
    "wambag -- 3,556\n",
    "OceanVortex -- 3,161\n",
    "ingalls_imports -- 2,794\n",
    "mapper999 -- 2,022\n",
    "morganwahl -- 1,509\n",
    "MassGIS Import -- 1,351\n",
    "cspanring -- 1,252\n",
    "cfogel -- 1,193\n",
    "\n",
    "234/771 have one made one edit.\n",
    "\n",
    "Total Way Edits: 267,373 for 128,389 way nodes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scope of This Project\n",
    "\n",
    "## Fixing Addresses\n",
    "\n",
    "With the above information, it seems the most valuable piece that I can contribute programmatically would be to edit the semi-permanent information, namely street addresses, since street name changes much less frequently than a business store front.\n",
    "\n",
    "One important means of standardization is to make sure all street names use the same convention. Cambridge is one of the oldest part of the United States. There are more unusual naming conventions. In addition to trying to convert a diverse range of abbreviations (St, st, ST, and St. for Street), there are a wide range of acceptable street name ending conventions. Here is a sample:\n",
    "\n",
    "```\n",
    "\"Street\"\n",
    "\"Avenue\"\n",
    "\"Boulevard\"\n",
    "\"Drive\"\n",
    "\"Court\"\n",
    "\"Place\"\n",
    "\"Square\"\n",
    "\"Lane\"\n",
    "\"Road\"\n",
    "\"Trail\"\n",
    "\"Parkway\"\n",
    "\"Commons\"\n",
    "\"Broadway\"\n",
    "\"Terrace\"\n",
    "\"Highway\"\n",
    "\"Way\"\n",
    "\"Circle\"\n",
    "\"Driveway\"\n",
    "\"Plaza\"\n",
    "\"Park\"\n",
    "\"Mall\"\n",
    "\"Fenway\"\n",
    "\"Row\"\n",
    "```\n",
    "\n",
    "I will convert abbreviations into the fully expanded term. It will make it easier for those to work with the database afterwards to choose their own abbreviates as policy rather than have it as a part of the mechanism.\n",
    "\n",
    "The address information is usually located within way tags and node tags \"value\" fields with \"addr\" as its type. In addition to street address, zip code, city, state, and even country information are also sometimes located in it. I will eliminate abbreviations used for city and state as well as for street addresses. I will shorten all zip code into its five digit format.\n",
    "\n",
    "I will use a simple substitution method for making the corrections. I will create a dictionary with words that I am looking to change as keys, and with the words to be changed to as the value. Whenever I encounter a key, I will replace it to the value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems Encounter and Potential Solutions\n",
    "\n",
    "## Poor Organization of Information\n",
    "\n",
    "The \"addr\" tag is associated with a wild variety of types of data. The associated value could be a zip code, a town name, a street number, or a combination of the above and more. As the result some associate values are overloaded with information, while others are underutilized.\n",
    "\n",
    "## Relying on Heuristic\n",
    "\n",
    "In order to minimize the amount of data that need to be hand coded, I relied on heuristics to narrow down problematic values that needed my individual attention. This means that I could be making type II errors.\n",
    "\n",
    "## Missing a Complete Picture\n",
    "\n",
    "In essence, I am trying to correct data on the level of individual words. The organization of the tag information already caused a fragmentation of information regarding the associated node. I am looking for correctness at the individual word level. Higher level syntax and semantics had to be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of the Data\n",
    "\n",
    "## Files\n",
    "\n",
    "```\n",
    "cambridge.xml -- 171 MB\n",
    "nodes.csv ------  60 MB\n",
    "nodes_tags.csv -   4 MB\n",
    "ways.csv -------   8 MB\n",
    "ways_nodes.csv -  22 MB\n",
    "ways_tags.csv --  10 MB\n",
    "cambridge.db ---  90 MB\n",
    "```\n",
    "\n",
    "## Data\n",
    "\n",
    "```\n",
    "Nodes -- 755,341\n",
    "Ways  -- 128,389\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating the Data\n",
    "\n",
    "## Cameras and Surveillance\n",
    "\n",
    "Privacy is becoming a more and more prevalent concern. When I encountered 'camera' type in nodes tags, I became immediately interested. I was curious to see how common these cameras were.\n",
    "\n",
    "```SQL\n",
    "SELECT COUNT(*) FROM nodes_tags WHERE type LIKE \"%camera%\"\n",
    "```\n",
    "\n",
    "```SQL\n",
    "236\n",
    "```\n",
    "\n",
    "```SQL\n",
    "SELECT COUNT(*) FROM nodes_tags WHERE type LIKE \"%surveillance%\"\n",
    "```\n",
    "\n",
    "```SQL\n",
    "207\n",
    "```\n",
    "\n",
    "Luckily, it does not seem to be widespread yet, at the time when the data was captured. However, I also must wonder if there might not be many more cameras that are more well hidden.\n",
    "\n",
    "## Parking\n",
    "\n",
    "Parking in Cambridge can be very expensive. The daily parking rate for parking garages in the busiest parts of the city can cost $40+. Therefore, I am always on the lookout for good parking spots.\n",
    "\n",
    "```SQL\n",
    "SELECT COUNT(*) FROM ways_tags WHERE type LIKE \"%parking%\";\n",
    "```\n",
    "\n",
    "```SQL\n",
    "128\n",
    "```\n",
    "\n",
    "Compared with the number of nodes for the city, the records for street parking is surprising few. Perhaps, this is why I, and probably many others must constantly try to find good parking spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas for Future\n",
    "\n",
    "One limitation of my approach is that the corrections is limited to individual word level. In order to programmatically make semantic level corrections, I would need some way to reading all ways tags for a ways node, make sense of the information therein, and restructure the information in such a way that it makes sense for the next person or program that acquires the data. At this moment, I do not have a good way to do that. However, I think that would be a good goal to work towards.\n",
    "\n",
    "One potential improvement on my current procedure might be to expand the looping structure for how I approached data cleaning. The approach that I took repeatedly went through the XML data. Between each time, I would make adjustments to further improve the program logic. This limited me to making adjustment on the individual word level.\n",
    "\n",
    "If I had more time, I should integrate data exploration phase with data cleaning phase more tightly. Looking through the data during exploration, I noticed places where, even only making adjustment at word level, I could have improved the overall structure of the data.\n",
    "\n",
    "```SQL\n",
    "SELECT COUNT(*) FROM ways_tags WHERE type LIKE \"%addr2%\";\n",
    "```\n",
    "\n",
    "```SQL\n",
    "1\n",
    "```\n",
    "\n",
    "It wasn't until I looked at the data in the database, I noticed this very strange type. It would have been easily correctly during the data cleaning phase, if I had known. However, I could not have known until I had some preliminary results to work with.\n",
    "\n",
    "Finally, I opted not to use regular expression for finding problematic words. Instead, I found problematic words by matching them individually, and then made corrections. As I proceeded further in the project, I thought that using regular expression would have allowed me to ultimately proceed faster and make corrections at a higher level than individual words. If I were to redo this project, I will use regular expressions instead."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
